{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c101bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e70b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gold_omap_xlsx(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_excel(path, dtype=str).fillna(\"\")\n",
    "\n",
    "    # --- Split OMOP entity + attribute ---\n",
    "    df[[\"entity\", \"attribute\"]] = df[\"omop\"].str.split(\"-\", n=1, expand=True)\n",
    "\n",
    "    # --- Split MIMIC table + column ---\n",
    "    df[[\"gold_table\", \"gold_column\"]] = df[\"table\"].str.split(\"-\", n=1, expand=True)\n",
    "\n",
    "    # Keep only needed columns\n",
    "    df = df[[\"entity\", \"attribute\", \"gold_table\", \"gold_column\", \"label\"]]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10bcc6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mapping(mapping_json_path, gold_file_path):\n",
    "    if not gold_file_path:\n",
    "        print(\"No gold file provided — skipping evaluation.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n=== Running Evaluation using GOLD dataset: {gold_file_path} ===\")\n",
    "\n",
    "    # ---- Load predictions ----\n",
    "    with open(mapping_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        pred = json.load(f)\n",
    "\n",
    "    pred_entities = pred[\"mapping\"]\n",
    "\n",
    "    # ---- Load gold ----\n",
    "    file_ext = gold_file_path.split(\".\")[-1].lower()\n",
    "\n",
    "    if file_ext == \"xlsx\":\n",
    "        raw = pd.read_excel(gold_file_path, dtype=str).fillna(\"\")\n",
    "        gold = load_gold_omap_xlsx(gold_file_path)\n",
    "    elif file_ext == \"csv\":\n",
    "        gold = pd.read_csv(gold_file_path, dtype=str)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported gold file type: {file_ext}\")\n",
    "    \n",
    "    gold[\"entity\"] = gold[\"entity\"].str.lower()\n",
    "    gold[\"attribute\"] = gold[\"attribute\"].str.lower()\n",
    "    gold[\"gold_table\"] = gold[\"gold_table\"].str.lower()\n",
    "    gold[\"gold_column\"] = gold[\"gold_column\"].str.lower()\n",
    "\n",
    "    # ---- Build prediction DF ----\n",
    "    rows = []\n",
    "    for ent in pred_entities:\n",
    "        e = ent[\"entity\"].lower()\n",
    "        matched_table = ent.get(\"matched_table\") or \"\"\n",
    "\n",
    "        # Table-level prediction\n",
    "        rows.append({\n",
    "            \"entity\": e,\n",
    "            \"attribute\": None,\n",
    "            \"pred_table\": matched_table,\n",
    "            \"pred_column\": None\n",
    "        })\n",
    "\n",
    "        for attr in ent[\"attributes\"]:\n",
    "            rows.append({\n",
    "                \"entity\": e,\n",
    "                \"attribute\": attr[\"name\"].lower(),\n",
    "                \"pred_table\": matched_table,\n",
    "                \"pred_column\": (attr.get(\"target_column\") or \"\")\n",
    "            })\n",
    "\n",
    "    pred_df = pd.DataFrame(rows)\n",
    "\n",
    "    # ---- Table-level join ----\n",
    "    gold_tables = gold[[\"entity\", \"gold_table\"]].drop_duplicates()\n",
    "    table_eval = gold_tables.merge(\n",
    "        pred_df[pred_df[\"attribute\"].isna()],\n",
    "        on=\"entity\", how=\"left\"\n",
    "    )\n",
    "    table_eval[\"y_true\"] = table_eval[\"gold_table\"]\n",
    "    table_eval[\"y_pred\"] = table_eval[\"pred_table\"]\n",
    "\n",
    "    # ---- Column-level join ----\n",
    "    gold_cols = gold.dropna(subset=[\"attribute\"])\n",
    "    col_eval = gold_cols.merge(\n",
    "        pred_df[pred_df[\"attribute\"].notna()],\n",
    "        on=[\"entity\", \"attribute\"], how=\"left\"\n",
    "    )\n",
    "    col_eval[\"y_true\"] = col_eval[\"gold_column\"]\n",
    "    col_eval[\"y_pred\"] = col_eval[\"pred_column\"]\n",
    "\n",
    "    # ---- Metrics ----\n",
    "    print(\"\\n>>> TABLE-LEVEL METRICS\")\n",
    "    table_report = classification_report(table_eval[\"y_true\"], table_eval[\"y_pred\"], zero_division=0)\n",
    "    print(\"\\n\" + table_report)\n",
    "    table_cm = confusion_matrix(table_eval[\"y_true\"], table_eval[\"y_pred\"])\n",
    "    print(f\"Table-level Confusion Matrix:\\n{table_cm}\")\n",
    "\n",
    "    print(\"\\n>>> COLUMN-LEVEL METRICS\")\n",
    "    col_report = classification_report(col_eval[\"y_true\"], col_eval[\"y_pred\"], zero_division=0)\n",
    "    print(\"\\n\" + col_report)\n",
    "    col_cm = confusion_matrix(col_eval[\"y_true\"], col_eval[\"y_pred\"])\n",
    "    print(f\"Column-level Confusion Matrix:\\n{col_cm}\")\n",
    "\n",
    "    # ---- Save evaluation artifacts ----\n",
    "    eval_dir = Path(\"artifacts/evaluation\")\n",
    "    eval_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    table_eval.to_csv(eval_dir/\"table_eval.csv\", index=False)\n",
    "    col_eval.to_csv(eval_dir/\"column_eval.csv\", index=False)\n",
    "\n",
    "    with open(eval_dir/\"report.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"table_classification_report\": table_report,\n",
    "            \"table_confusion_matrix\": table_cm.tolist(),\n",
    "            \"column_classification_report\": col_report,\n",
    "            \"column_confusion_matrix\": col_cm.tolist(),\n",
    "        }, f, indent=2)\n",
    "\n",
    "    print(f\"\\nSaved evaluation results in: {eval_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d59a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Evaluation using GOLD dataset: ./omop_mimic_data.xlsx ===\n",
      "\n",
      ">>> TABLE-LEVEL METRICS\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "                         0.00      0.00      0.00         0\n",
      "        admissions       0.04      0.05      0.04        21\n",
      "           callout       0.00      0.00      0.00        21\n",
      "        caregivers       0.00      0.00      0.00        21\n",
      "       chartevents       0.04      0.05      0.04        21\n",
      "         cptevents       0.04      0.05      0.04        21\n",
      "             d_cpt       0.00      0.00      0.00        21\n",
      "   d_icd_diagnoses       0.00      0.00      0.00        21\n",
      "  d_icd_procedures       0.00      0.00      0.00        21\n",
      "           d_items       0.00      0.00      0.00        21\n",
      "        d_labitems       0.00      0.00      0.00        21\n",
      "    datetimeevents       0.00      0.00      0.00        21\n",
      "     diagnoses_icd       0.00      0.00      0.00        21\n",
      "          drgcodes       0.00      0.00      0.00        21\n",
      "          icustays       0.00      0.00      0.00        21\n",
      "    inputevents_cv       0.00      0.00      0.00        21\n",
      "    inputevents_mv       0.00      0.00      0.00        21\n",
      "         labevents       0.04      0.05      0.04        21\n",
      "microbiologyevents       0.00      0.00      0.00        21\n",
      "        noteevents       0.00      0.00      0.00        21\n",
      "             notes       0.00      0.00      0.00         0\n",
      "      outputevents       0.00      0.00      0.00        21\n",
      "          patients       0.04      0.05      0.04        21\n",
      "     prescriptions       0.04      0.10      0.06        21\n",
      "    procedures_icd       0.00      0.00      0.00        21\n",
      "          services       0.04      0.05      0.04        21\n",
      "         transfers       0.00      0.00      0.00        21\n",
      "\n",
      "          accuracy                           0.02       525\n",
      "         macro avg       0.01      0.01      0.01       525\n",
      "      weighted avg       0.01      0.02      0.01       525\n",
      "\n",
      "Table-level Confusion Matrix:\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]\n",
      " [12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  2\n",
      "   0  1  0]]\n",
      "\n",
      ">>> COLUMN-LEVEL METRICS\n",
      "\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "                                    0.00      0.00      0.00         0\n",
      "                    ab_itemid       0.00      0.00      0.00       267\n",
      "                      ab_name       0.00      0.00      0.00       267\n",
      "                 abbreviation       0.00      0.00      0.00       267\n",
      "           acknowledge_status       0.00      0.00      0.00       267\n",
      "              acknowledgetime       0.00      0.00      0.00       267\n",
      "               admission-type       0.00      0.00      0.00         0\n",
      "           admission_location       0.00      0.00      0.00       267\n",
      "               admission_type       0.00      0.00      0.00       267\n",
      "                     admitime       0.00      0.00      0.00         0\n",
      "                    admittime       0.00      0.00      0.00       267\n",
      "                       amount       0.00      0.00      0.00       534\n",
      "                    amountuom       0.00      0.00      0.00       534\n",
      "              callout_outcome       0.00      0.00      0.00       267\n",
      "              callout_service       0.00      0.00      0.00       267\n",
      "               callout_status       0.00      0.00      0.00       267\n",
      "               callout_wardid       0.00      0.00      0.00       267\n",
      "                 cancelreason       0.00      0.00      0.00       267\n",
      "                     category       0.00      0.00      0.00      1068\n",
      "                         cgid       0.00      0.00      0.00       267\n",
      "                    chartdate       0.01      0.00      0.01       801\n",
      "                    charttime       0.03      0.01      0.01      1869\n",
      "          comments_canceledby       0.00      0.00      0.00       267\n",
      "                comments_date       0.00      0.00      0.00       267\n",
      "            comments_editedby       0.00      0.00      0.00       267\n",
      "                    conceptid       0.00      0.00      0.00       267\n",
      "           continueinnextdept       0.00      0.00      0.00       267\n",
      "                   costcenter       0.00      0.00      0.00       267\n",
      "                       cpt_cd       0.00      0.00      0.00       267\n",
      "                   cpt_number       0.00      0.00      0.00       267\n",
      "                   cpt_suffix       0.00      0.00      0.00       267\n",
      "                   createtime       0.00      0.00      0.00       267\n",
      "                curr_careunit       0.01      0.00      0.01       534\n",
      "                 curr_service       0.00      0.00      0.00       267\n",
      "                  curr_wardid       0.00      0.00      0.00       534\n",
      "       currentreservationtime       0.00      0.00      0.00       267\n",
      "                     dbsource       0.00      0.00      0.00       801\n",
      "                    deathtime       0.00      0.00      0.00       267\n",
      "                  description       0.00      0.00      0.00      1068\n",
      "                    diagnosis       0.00      0.00      0.00       267\n",
      "          dilution_comparison       0.00      0.00      0.00       267\n",
      "                dilution_text       0.00      0.00      0.00       267\n",
      "               dilution_value       0.00      0.00      0.00       267\n",
      "             discharge_wardid       0.00      0.00      0.00       267\n",
      "                    dischtime       0.00      0.01      0.01       267\n",
      "                          dob       0.00      0.02      0.01       267\n",
      "                          dod       0.00      0.01      0.01       267\n",
      "                     dod_hosp       0.00      0.00      0.00       267\n",
      "                      dod_ssn       0.00      0.00      0.00       267\n",
      "                 dose_unit_rx       0.00      0.00      0.00       267\n",
      "                  dose_val_rx       0.00      0.00      0.00       267\n",
      "                     drg_code       0.00      0.00      0.00       267\n",
      "                drg_mortality       0.00      0.00      0.00       267\n",
      "                 drg_severity       0.00      0.00      0.00       267\n",
      "                     drg_type       0.00      0.00      0.00       267\n",
      "                         drug       0.00      0.00      0.00       267\n",
      "            drug_name_generic       0.00      0.00      0.00       267\n",
      "                drug_name_poe       0.00      0.00      0.00       267\n",
      "                    drug_type       0.00      0.00      0.00       267\n",
      "                    edouttime       0.00      0.00      0.00       267\n",
      "                    edregtime       0.00      0.00      0.00       267\n",
      "                      enddate       0.00      0.00      0.00       267\n",
      "                      endtime       0.00      0.00      0.00       267\n",
      "                        error       0.00      0.00      0.00       534\n",
      "                    ethnicity       0.00      0.00      0.00       267\n",
      "                    eventtype       0.00      0.00      0.00       267\n",
      "                  expire_flag       0.00      0.00      0.00       267\n",
      "               first_careunit       0.00      0.00      0.00       267\n",
      "                 first_wardid       0.00      0.00      0.00       267\n",
      "         firstreservationtime       0.00      0.00      0.00       267\n",
      "                         flag       0.00      0.00      0.00       267\n",
      "                        fluid       0.00      0.00      0.00       267\n",
      "               form_unit_disp       0.00      0.00      0.00       267\n",
      "                form_val_disp       0.00      0.00      0.00       267\n",
      "            formulary_drug_cd       0.00      0.00      0.00       267\n",
      "                       gender       0.00      0.01      0.01       267\n",
      "                          gsn       0.00      0.00      0.00       267\n",
      "                      hadm_id       0.00      0.01      0.01       267\n",
      "                      hamd_id       0.00      0.00      0.00         0\n",
      "         hospital_expire_flag       0.00      0.00      0.00       267\n",
      "                    icd9_code       0.00      0.00      0.00       534\n",
      "                   icustay_id       0.00      0.00      0.00       267\n",
      "                    insurance       0.00      0.00      0.00       267\n",
      "               interpretation       0.00      0.00      0.00       267\n",
      "                       intime       0.00      0.00      0.00       534\n",
      "                      iserror       0.00      0.00      0.00       534\n",
      "                  isolate_num       0.00      0.00      0.00       267\n",
      "                    isopenbag       0.00      0.00      0.00       267\n",
      "                       itemid       0.00      0.00      0.00       801\n",
      "                        label       0.00      0.00      0.00       801\n",
      "                 labevents_id       0.00      0.00      0.00         0\n",
      "                     language       0.00      0.00      0.00       267\n",
      "                last_careunit       0.00      0.00      0.00       267\n",
      "                  last_wardid       0.00      0.00      0.00       267\n",
      "                  linkorderid       0.00      0.00      0.00       534\n",
      "                      linksto       0.00      0.00      0.00       267\n",
      "                   loinc_code       0.00      0.00      0.00       267\n",
      "                   long_title       0.00      0.00      0.00       534\n",
      "                          los       0.00      0.00      0.00       534\n",
      "               marital_status       0.00      0.00      0.00       267\n",
      "          maxcodeinsubsection       0.00      0.00      0.00       267\n",
      "                     mimic_id       0.00      0.00      0.00      6675\n",
      "          mincodeinsubsection       0.00      0.00      0.00       267\n",
      "                 mv_starttime       0.00      0.00      0.00         0\n",
      "                          ndc       0.00      0.00      0.00       267\n",
      "                    newbottle       0.00      0.00      0.00       534\n",
      "     ordercategorydescription       0.00      0.00      0.00       267\n",
      "            ordercategoryname       0.00      0.00      0.00       267\n",
      "ordercomponenttypedescription       0.00      0.00      0.00       267\n",
      "                      orderid       0.00      0.00      0.00       534\n",
      "                   org_itemid       0.00      0.00      0.00       267\n",
      "                     org_name       0.00      0.00      0.00       267\n",
      "               originalamount       0.00      0.00      0.00       534\n",
      "            originalamountuom       0.00      0.00      0.00       267\n",
      "                 originalrate       0.00      0.00      0.00       534\n",
      "              originalrateuom       0.00      0.00      0.00       267\n",
      "                originalroute       0.00      0.00      0.00       267\n",
      "                 originalsite       0.00      0.00      0.00       267\n",
      "                  outcometime       0.00      0.00      0.00       267\n",
      "                      outtime       0.01      0.00      0.01       534\n",
      "                   param_type       0.00      0.00      0.00       267\n",
      "                patientweight       0.00      0.00      0.00       267\n",
      "                prev_careunit       0.00      0.00      0.00       267\n",
      "                 prev_service       0.00      0.00      0.00       267\n",
      "                  prev_wardid       0.00      0.00      0.00       267\n",
      "                prod_strength       0.00      0.00      0.00       267\n",
      "                         rate       0.00      0.00      0.00       534\n",
      "                      rateuom       0.00      0.00      0.00       534\n",
      "                     religion       0.00      0.00      0.00       267\n",
      "                request_cdiff       0.00      0.00      0.00       267\n",
      "                 request_mrsa       0.00      0.00      0.00       267\n",
      "                 request_resp       0.00      0.00      0.00       267\n",
      "                 request_tele       0.00      0.00      0.00       267\n",
      "                  request_vre       0.00      0.00      0.00       267\n",
      "                 resultstatus       0.00      0.00      0.00       534\n",
      "                        route       0.00      0.00      0.00       267\n",
      "                       row_id       0.00      0.00      0.00         0\n",
      "   secondaryordercategoryname       0.00      0.00      0.00       267\n",
      "                sectionheader       0.00      0.00      0.00       534\n",
      "                 sectionrange       0.00      0.00      0.00       267\n",
      "                      seq_num       0.00      0.00      0.00       534\n",
      "                   service_id       0.00      0.00      0.00         0\n",
      "                  short_title       0.00      0.00      0.00       534\n",
      "                  spec_itemid       0.00      0.00      0.00       267\n",
      "               spec_type_desc       0.00      0.00      0.00       267\n",
      "                    startdate       0.00      0.00      0.00       267\n",
      "                    starttime       0.00      0.00      0.00       267\n",
      "            statusdescription       0.00      0.00      0.00       267\n",
      "                      stopped       0.00      0.00      0.00      1068\n",
      "                    storetime       0.00      0.00      0.00      1068\n",
      "                   subject_id       0.00      0.05      0.01       267\n",
      "              submit_careunit       0.00      0.00      0.00       267\n",
      "                submit_wardid       0.00      0.00      0.00       267\n",
      "             subsectionheader       0.00      0.00      0.00       534\n",
      "              subsectionrange       0.00      0.00      0.00       267\n",
      "                         text       0.00      0.00      0.00       267\n",
      "                ticket_id_seq       0.00      0.00      0.00       267\n",
      "                  totalamount       0.00      0.00      0.00       267\n",
      "               totalamountuom       0.00      0.00      0.00       267\n",
      "                 transfertime       0.00      0.01      0.01       267\n",
      "                     unitname       0.00      0.00      0.00       267\n",
      "                   updatetime       0.00      0.00      0.00       267\n",
      "                        value       0.02      0.00      0.01      1068\n",
      "                     valuenum       0.00      0.00      0.00       801\n",
      "                     valueuom       0.02      0.00      0.01      1068\n",
      "                      warning       0.00      0.00      0.00       534\n",
      "\n",
      "                     accuracy                           0.00     64080\n",
      "                    macro avg       0.00      0.00      0.00     64080\n",
      "                 weighted avg       0.00      0.00      0.00     64080\n",
      "\n",
      "Column-level Confusion Matrix:\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [218   0   0 ...   0   1   0]\n",
      " [218   0   0 ...   0   1   0]\n",
      " ...\n",
      " [654   0   0 ...   0   3   0]\n",
      " [872   0   0 ...   0   4   0]\n",
      " [436   0   0 ...   0   2   0]]\n",
      "\n",
      "Saved evaluation results in: artifacts\\evaluation\n"
     ]
    }
   ],
   "source": [
    "evaluate_mapping(\"./mapping_report.json\", \"./omop_mimic_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8df61d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Evaluation using GOLD dataset: ./omop_mimic_data.xlsx ===\n",
      "\n",
      ">>> TABLE-LEVEL METRICS (Binary)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9274    0.9733    0.9498       525\n",
      "           1     0.3000    0.1304    0.1818        46\n",
      "\n",
      "    accuracy                         0.9054       571\n",
      "   macro avg     0.6137    0.5519    0.5658       571\n",
      "weighted avg     0.8769    0.9054    0.8879       571\n",
      "\n",
      "Table Confusion Matrix:\n",
      " [[511  14]\n",
      " [ 40   6]]\n",
      "\n",
      ">>> COLUMN-LEVEL METRICS (Binary)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9981    0.9972    0.9977     63951\n",
      "           1     0.0378    0.0543    0.0446       129\n",
      "\n",
      "    accuracy                         0.9953     64080\n",
      "   macro avg     0.5180    0.5257    0.5211     64080\n",
      "weighted avg     0.9962    0.9953    0.9957     64080\n",
      "\n",
      "Column Confusion Matrix:\n",
      " [[63773   178]\n",
      " [  122     7]]\n",
      "\n",
      "Saved evaluation results to: artifacts\\evaluation\n"
     ]
    }
   ],
   "source": [
    "def evaluate_mapping(mapping_json_path, gold_file_path):\n",
    "    if not gold_file_path:\n",
    "        print(\"No gold file provided — skipping evaluation.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n=== Running Evaluation using GOLD dataset: {gold_file_path} ===\")\n",
    "\n",
    "    # ---- Load predictions ----\n",
    "    with open(mapping_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        pred = json.load(f)\n",
    "\n",
    "    pred_entities = pred[\"mapping\"]\n",
    "\n",
    "    # ---- Load gold ----\n",
    "    file_ext = gold_file_path.split(\".\")[-1].lower()\n",
    "\n",
    "    if file_ext == \"xlsx\":\n",
    "        gold = load_gold_omap_xlsx(gold_file_path)\n",
    "    elif file_ext == \"csv\":\n",
    "        gold = pd.read_csv(gold_file_path, dtype=str)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported gold file type: {file_ext}\")\n",
    "\n",
    "    # Normalize fields\n",
    "    gold[\"entity\"] = gold[\"entity\"].str.lower()\n",
    "    gold[\"attribute\"] = gold[\"attribute\"].str.lower()\n",
    "    gold[\"gold_table\"] = gold[\"gold_table\"].str.lower()\n",
    "    gold[\"gold_column\"] = gold[\"gold_column\"].str.lower()\n",
    "\n",
    "    # Convert label to int if needed\n",
    "    gold[\"label\"] = gold[\"label\"].astype(int)\n",
    "\n",
    "    # ---- Build prediction DF ----\n",
    "    rows = []\n",
    "    for ent in pred_entities:\n",
    "        e = ent[\"entity\"].lower()\n",
    "        matched_table = (ent.get(\"matched_table\") or \"\").lower()\n",
    "\n",
    "        # Table-level prediction row\n",
    "        rows.append({\n",
    "            \"entity\": e,\n",
    "            \"attribute\": None,\n",
    "            \"pred_table\": matched_table,\n",
    "            \"pred_column\": None\n",
    "        })\n",
    "\n",
    "        # Attribute-level prediction rows\n",
    "        for attr in ent[\"attributes\"]:\n",
    "            rows.append({\n",
    "                \"entity\": e,\n",
    "                \"attribute\": attr[\"name\"].lower(),\n",
    "                \"pred_table\": matched_table,\n",
    "                \"pred_column\": (attr.get(\"target_column\") or \"\").lower()\n",
    "            })\n",
    "\n",
    "    pred_df = pd.DataFrame(rows)\n",
    "\n",
    "    # ============================================================\n",
    "    # TABLE-LEVEL BINARY EVALUATION\n",
    "    # ============================================================\n",
    "\n",
    "    gold_tables = gold[[\"entity\", \"gold_table\", \"label\"]].drop_duplicates()\n",
    "\n",
    "    table_eval = gold_tables.merge(\n",
    "        pred_df[pred_df[\"attribute\"].isna()],\n",
    "        on=\"entity\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # y_true = gold label\n",
    "    table_eval[\"y_true\"] = table_eval[\"label\"]\n",
    "\n",
    "    # y_pred = 1 if predicted_table == gold_table else 0\n",
    "    table_eval[\"y_pred\"] = (table_eval[\"pred_table\"] == table_eval[\"gold_table\"]).astype(int)\n",
    "\n",
    "    print(\"\\n>>> TABLE-LEVEL METRICS (Binary)\")\n",
    "    table_report = classification_report(\n",
    "        table_eval[\"y_true\"], table_eval[\"y_pred\"],\n",
    "        digits=4, zero_division=0\n",
    "    )\n",
    "    print(table_report)\n",
    "\n",
    "    table_cm = confusion_matrix(table_eval[\"y_true\"], table_eval[\"y_pred\"])\n",
    "    print(\"Table Confusion Matrix:\\n\", table_cm)\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # COLUMN-LEVEL BINARY EVALUATION\n",
    "    # ============================================================\n",
    "\n",
    "    gold_cols = gold.dropna(subset=[\"attribute\"])\n",
    "\n",
    "    col_eval = gold_cols.merge(\n",
    "        pred_df[pred_df[\"attribute\"].notna()],\n",
    "        on=[\"entity\", \"attribute\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # y_true = gold label\n",
    "    col_eval[\"y_true\"] = col_eval[\"label\"]\n",
    "\n",
    "    # y_pred = 1 if predicted_column == gold_column else 0\n",
    "    col_eval[\"y_pred\"] = (col_eval[\"pred_column\"] == col_eval[\"gold_column\"]).astype(int)\n",
    "\n",
    "    print(\"\\n>>> COLUMN-LEVEL METRICS (Binary)\")\n",
    "    col_report = classification_report(\n",
    "        col_eval[\"y_true\"], col_eval[\"y_pred\"],\n",
    "        digits=4, zero_division=0\n",
    "    )\n",
    "    print(col_report)\n",
    "\n",
    "    col_cm = confusion_matrix(col_eval[\"y_true\"], col_eval[\"y_pred\"])\n",
    "    print(\"Column Confusion Matrix:\\n\", col_cm)\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # SAVE ARTIFACTS\n",
    "    # ============================================================\n",
    "\n",
    "    eval_dir = Path(\"artifacts/evaluation\")\n",
    "    eval_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    table_eval.to_csv(eval_dir / \"table_eval_binary.csv\", index=False)\n",
    "    col_eval.to_csv(eval_dir / \"column_eval_binary.csv\", index=False)\n",
    "\n",
    "    with open(eval_dir / \"binary_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"table_report\": table_report,\n",
    "            \"table_confusion_matrix\": table_cm.tolist(),\n",
    "            \"column_report\": col_report,\n",
    "            \"column_confusion_matrix\": col_cm.tolist(),\n",
    "        }, f, indent=2)\n",
    "\n",
    "    print(f\"\\nSaved evaluation results to: {eval_dir}\")\n",
    "evaluate_mapping(\"./mapping_imputed.json\", \"./omop_mimic_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6047d398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Evaluation using GOLD dataset: ./omop_mimic_data.xlsx ===\n",
      "\n",
      ">>> TABLE-LEVEL METRICS (Binary)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9299    0.9848    0.9565       525\n",
      "           1     0.4667    0.1522    0.2295        46\n",
      "\n",
      "    accuracy                         0.9177       571\n",
      "   macro avg     0.6983    0.5685    0.5930       571\n",
      "weighted avg     0.8925    0.9177    0.8980       571\n",
      "\n",
      "Table Confusion Matrix:\n",
      " [[517   8]\n",
      " [ 39   7]]\n",
      "\n",
      ">>> COLUMN-LEVEL METRICS (Binary)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9983    0.9994    0.9989     63951\n",
      "           1     0.3710    0.1783    0.2408       129\n",
      "\n",
      "    accuracy                         0.9977     64080\n",
      "   macro avg     0.6847    0.5888    0.6199     64080\n",
      "weighted avg     0.9971    0.9977    0.9973     64080\n",
      "\n",
      "Column Confusion Matrix:\n",
      " [[63912    39]\n",
      " [  106    23]]\n",
      "\n",
      "Saved evaluation results to: artifacts\\evaluation\n"
     ]
    }
   ],
   "source": [
    "def evaluate_mapping(mapping_json_path, gold_file_path, threshold=0.90):\n",
    "    if not gold_file_path:\n",
    "        print(\"No gold file provided — skipping evaluation.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n=== Running Evaluation using GOLD dataset: {gold_file_path} ===\")\n",
    "\n",
    "    # ---- Load predictions ----\n",
    "    with open(mapping_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        pred = json.load(f)\n",
    "\n",
    "    pred_entities = pred[\"mapping\"]\n",
    "\n",
    "    # ---- Load gold ----\n",
    "    file_ext = gold_file_path.split(\".\")[-1].lower()\n",
    "\n",
    "    if file_ext == \"xlsx\":\n",
    "        gold = load_gold_omap_xlsx(gold_file_path)\n",
    "    elif file_ext == \"csv\":\n",
    "        gold = pd.read_csv(gold_file_path, dtype=str)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported gold file type: {file_ext}\")\n",
    "\n",
    "    # Normalize fields\n",
    "    gold[\"entity\"] = gold[\"entity\"].str.lower()\n",
    "    gold[\"attribute\"] = gold[\"attribute\"].str.lower()\n",
    "    gold[\"gold_table\"] = gold[\"gold_table\"].str.lower()\n",
    "    gold[\"gold_column\"] = gold[\"gold_column\"].str.lower()\n",
    "\n",
    "    # Convert label to int if needed\n",
    "    gold[\"label\"] = gold[\"label\"].astype(int)\n",
    "\n",
    "    # ---- Build prediction DF ----\n",
    "    rows = []\n",
    "    for ent in pred_entities:\n",
    "        e = ent[\"entity\"].lower()\n",
    "        matched_table = (ent.get(\"matched_table\") or \"\").lower()\n",
    "\n",
    "        # Table-level prediction row\n",
    "        rows.append({\n",
    "            \"entity\": e,\n",
    "            \"attribute\": None,\n",
    "            \"pred_table\": matched_table,\n",
    "            \"pred_column\": None\n",
    "        })\n",
    "\n",
    "        # Attribute-level prediction rows\n",
    "        for attr in ent[\"attributes\"]:\n",
    "            rows.append({\n",
    "                \"entity\": e,\n",
    "                \"attribute\": attr[\"name\"].lower(),\n",
    "                \"pred_table\": matched_table,\n",
    "                \"pred_column\": (attr.get(\"target_column\") or \"\").lower()\n",
    "            })\n",
    "\n",
    "    pred_df = pd.DataFrame(rows)\n",
    "\n",
    "    # ============================================================\n",
    "    # TABLE-LEVEL BINARY EVALUATION\n",
    "    # ============================================================\n",
    "\n",
    "    gold_tables = gold[[\"entity\", \"gold_table\", \"label\"]].drop_duplicates()\n",
    "\n",
    "    table_eval = gold_tables.merge(\n",
    "        pred_df[pred_df[\"attribute\"].isna()],\n",
    "        on=\"entity\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    conf_map = {e[\"entity\"].lower(): e.get(\"table_confidence\", 0.0)\n",
    "            for e in pred_entities}\n",
    "\n",
    "    table_eval[\"table_confidence\"] = table_eval[\"entity\"].map(conf_map)\n",
    "\n",
    "    # y_true = gold label\n",
    "    table_eval[\"y_true\"] = table_eval[\"label\"]\n",
    "\n",
    "    table_eval[\"y_pred\"] = (\n",
    "            (table_eval[\"pred_table\"] == table_eval[\"gold_table\"]) &\n",
    "            (table_eval[\"table_confidence\"] >= threshold)\n",
    "        ).astype(int)\n",
    "\n",
    "    print(\"\\n>>> TABLE-LEVEL METRICS (Binary)\")\n",
    "    table_report = classification_report(\n",
    "        table_eval[\"y_true\"], table_eval[\"y_pred\"],\n",
    "        digits=4, zero_division=0\n",
    "    )\n",
    "    print(table_report)\n",
    "\n",
    "    table_cm = confusion_matrix(table_eval[\"y_true\"], table_eval[\"y_pred\"])\n",
    "    print(\"Table Confusion Matrix:\\n\", table_cm)\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # COLUMN-LEVEL BINARY EVALUATION\n",
    "    # ============================================================\n",
    "\n",
    "    gold_cols = gold.dropna(subset=[\"attribute\"])\n",
    "\n",
    "    col_eval = gold_cols.merge(\n",
    "        pred_df[pred_df[\"attribute\"].notna()],\n",
    "        on=[\"entity\", \"attribute\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # y_true = gold label\n",
    "    col_eval[\"y_true\"] = col_eval[\"label\"]\n",
    "\n",
    "    # y_pred = 1 if predicted_column == gold_column else 0\n",
    "    col_eval[\"y_pred\"] = (col_eval[\"pred_column\"] == col_eval[\"gold_column\"]).astype(int)\n",
    "\n",
    "    print(\"\\n>>> COLUMN-LEVEL METRICS (Binary)\")\n",
    "    col_report = classification_report(\n",
    "        col_eval[\"y_true\"], col_eval[\"y_pred\"],\n",
    "        digits=4, zero_division=0\n",
    "    )\n",
    "    print(col_report)\n",
    "\n",
    "    col_cm = confusion_matrix(col_eval[\"y_true\"], col_eval[\"y_pred\"])\n",
    "    print(\"Column Confusion Matrix:\\n\", col_cm)\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # SAVE ARTIFACTS\n",
    "    # ============================================================\n",
    "\n",
    "    eval_dir = Path(\"artifacts/evaluation\")\n",
    "    eval_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    table_eval.to_csv(eval_dir / \"table_eval_binary.csv\", index=False)\n",
    "    col_eval.to_csv(eval_dir / \"column_eval_binary.csv\", index=False)\n",
    "\n",
    "    with open(eval_dir / \"binary_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"table_report\": table_report,\n",
    "            \"table_confusion_matrix\": table_cm.tolist(),\n",
    "            \"column_report\": col_report,\n",
    "            \"column_confusion_matrix\": col_cm.tolist(),\n",
    "        }, f, indent=2)\n",
    "\n",
    "    print(f\"\\nSaved evaluation results to: {eval_dir}\")\n",
    "evaluate_mapping(\"./mapping_report.json\", \"./omop_mimic_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8896eee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Evaluation using GOLD dataset: ./omop_mimic_data.xlsx ===\n",
      "\n",
      ">>> TABLE-LEVEL METRICS (Binary)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9194    1.0000    0.9580       525\n",
      "           1     0.0000    0.0000    0.0000        46\n",
      "\n",
      "    accuracy                         0.9194       571\n",
      "   macro avg     0.4597    0.5000    0.4790       571\n",
      "weighted avg     0.8454    0.9194    0.8808       571\n",
      "\n",
      "Table Confusion Matrix:\n",
      " [[525   0]\n",
      " [ 46   0]]\n",
      "\n",
      ">>> COLUMN-LEVEL METRICS (Binary)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9980    0.9988    0.9984     63951\n",
      "           1     0.0256    0.0155    0.0193       129\n",
      "\n",
      "    accuracy                         0.9968     64080\n",
      "   macro avg     0.5118    0.5072    0.5089     64080\n",
      "weighted avg     0.9961    0.9968    0.9964     64080\n",
      "\n",
      "Column Confusion Matrix:\n",
      " [[63875    76]\n",
      " [  127     2]]\n",
      "\n",
      "Saved evaluation results to: artifacts\\evaluation\n"
     ]
    }
   ],
   "source": [
    "def evaluate_mapping(mapping_json_path, gold_file_path, threshold=0.25):\n",
    "    if not gold_file_path:\n",
    "        print(\"No gold file provided — skipping evaluation.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n=== Running Evaluation using GOLD dataset: {gold_file_path} ===\")\n",
    "\n",
    "    # ---- Load predictions ----\n",
    "    with open(mapping_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        pred = json.load(f)\n",
    "\n",
    "    pred_entities = pred[\"mapping\"]\n",
    "\n",
    "    # ---- Load gold ----\n",
    "    file_ext = gold_file_path.split(\".\")[-1].lower()\n",
    "\n",
    "    if file_ext == \"xlsx\":\n",
    "        gold = load_gold_omap_xlsx(gold_file_path)\n",
    "    elif file_ext == \"csv\":\n",
    "        gold = pd.read_csv(gold_file_path, dtype=str)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported gold file type: {file_ext}\")\n",
    "\n",
    "    # Normalize fields\n",
    "    gold[\"entity\"] = gold[\"entity\"].str.lower()\n",
    "    gold[\"attribute\"] = gold[\"attribute\"].str.lower()\n",
    "    gold[\"gold_table\"] = gold[\"gold_table\"].str.lower()\n",
    "    gold[\"gold_column\"] = gold[\"gold_column\"].str.lower()\n",
    "\n",
    "    # Convert label to int if needed\n",
    "    gold[\"label\"] = gold[\"label\"].astype(int)\n",
    "\n",
    "    # ---- Build prediction DF ----\n",
    "    rows = []\n",
    "    for ent in pred_entities:\n",
    "        e = ent[\"entity\"].lower()\n",
    "        matched_table = (ent.get(\"matched_table\") or \"\").lower()\n",
    "\n",
    "        # Table-level prediction row\n",
    "        rows.append({\n",
    "            \"entity\": e,\n",
    "            \"attribute\": None,\n",
    "            \"pred_table\": matched_table,\n",
    "            \"pred_column\": None\n",
    "        })\n",
    "\n",
    "        # Attribute-level prediction rows\n",
    "        for attr in ent[\"attributes\"]:\n",
    "            rows.append({\n",
    "                \"entity\": e,\n",
    "                \"attribute\": attr[\"name\"].lower(),\n",
    "                \"pred_table\": matched_table,\n",
    "                \"pred_column\": (attr.get(\"target_column\") or \"\").lower()\n",
    "            })\n",
    "\n",
    "    pred_df = pd.DataFrame(rows)\n",
    "\n",
    "    # ============================================================\n",
    "    # TABLE-LEVEL BINARY EVALUATION\n",
    "    # ============================================================\n",
    "\n",
    "    gold_tables = gold[[\"entity\", \"gold_table\", \"label\"]].drop_duplicates()\n",
    "\n",
    "    table_eval = gold_tables.merge(\n",
    "        pred_df[pred_df[\"attribute\"].isna()],\n",
    "        on=\"entity\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    conf_map = {e[\"entity\"].lower(): e.get(\"table_confidence\", 0.0)\n",
    "            for e in pred_entities}\n",
    "\n",
    "    table_eval[\"table_confidence\"] = table_eval[\"entity\"].map(conf_map)\n",
    "\n",
    "    # y_true = gold label\n",
    "    table_eval[\"y_true\"] = table_eval[\"label\"]\n",
    "\n",
    "    table_eval[\"y_pred\"] = (\n",
    "            (table_eval[\"pred_table\"] == table_eval[\"gold_table\"]) &\n",
    "            (table_eval[\"table_confidence\"] >= threshold)\n",
    "        ).astype(int)\n",
    "\n",
    "    print(\"\\n>>> TABLE-LEVEL METRICS (Binary)\")\n",
    "    table_report = classification_report(\n",
    "        table_eval[\"y_true\"], table_eval[\"y_pred\"],\n",
    "        digits=4, zero_division=0\n",
    "    )\n",
    "    print(table_report)\n",
    "\n",
    "    table_cm = confusion_matrix(table_eval[\"y_true\"], table_eval[\"y_pred\"])\n",
    "    print(\"Table Confusion Matrix:\\n\", table_cm)\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # COLUMN-LEVEL BINARY EVALUATION\n",
    "    # ============================================================\n",
    "\n",
    "    # ============================================================\n",
    "# COLUMN-LEVEL BINARY EVALUATION (WITH CONFIDENCE)\n",
    "# ============================================================\n",
    "\n",
    "    gold_cols = gold.dropna(subset=[\"attribute\"])\n",
    "\n",
    "    # Build lookup for column confidence\n",
    "    col_conf_map = {}\n",
    "    for ent in pred_entities:\n",
    "        e = ent[\"entity\"].lower()\n",
    "        for attr in ent[\"attributes\"]:\n",
    "            a = attr[\"name\"].lower()\n",
    "            col_conf_map[(e, a)] = attr.get(\"confidence\", 0.0)\n",
    "\n",
    "    col_eval = gold_cols.merge(\n",
    "        pred_df[pred_df[\"attribute\"].notna()],\n",
    "        on=[\"entity\", \"attribute\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # y_true = gold label\n",
    "    col_eval[\"y_true\"] = col_eval[\"label\"]\n",
    "\n",
    "    # Inject column confidence\n",
    "    col_eval[\"column_confidence\"] = col_eval.apply(\n",
    "        lambda row: col_conf_map.get((row[\"entity\"], row[\"attribute\"]), 0.0),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Apply threshold:\n",
    "    col_threshold = threshold  # you can use config[\"column_threshold\"] if needed\n",
    "\n",
    "    col_eval[\"y_pred\"] = (\n",
    "        (col_eval[\"pred_column\"] == col_eval[\"gold_column\"]) &\n",
    "        (col_eval[\"column_confidence\"] >= col_threshold)\n",
    "    ).astype(int)\n",
    "\n",
    "    print(\"\\n>>> COLUMN-LEVEL METRICS (Binary)\")\n",
    "    col_report = classification_report(\n",
    "        col_eval[\"y_true\"], col_eval[\"y_pred\"],\n",
    "        digits=4, zero_division=0\n",
    "    )\n",
    "    print(col_report)\n",
    "\n",
    "    col_cm = confusion_matrix(col_eval[\"y_true\"], col_eval[\"y_pred\"])\n",
    "    print(\"Column Confusion Matrix:\\n\", col_cm)\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # SAVE ARTIFACTS\n",
    "    # ============================================================\n",
    "\n",
    "    eval_dir = Path(\"artifacts/evaluation\")\n",
    "    eval_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    table_eval.to_csv(eval_dir / \"table_eval_binary.csv\", index=False)\n",
    "    col_eval.to_csv(eval_dir / \"column_eval_binary.csv\", index=False)\n",
    "\n",
    "    with open(eval_dir / \"binary_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"table_report\": table_report,\n",
    "            \"table_confusion_matrix\": table_cm.tolist(),\n",
    "            \"column_report\": col_report,\n",
    "            \"column_confusion_matrix\": col_cm.tolist(),\n",
    "        }, f, indent=2)\n",
    "\n",
    "    print(f\"\\nSaved evaluation results to: {eval_dir}\")\n",
    "evaluate_mapping(\"./mapping_imputed.json\", \"./omop_mimic_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe5567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
